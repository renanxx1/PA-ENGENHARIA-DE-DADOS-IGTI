apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-processing-s22
  namespace: spark
spec:
  timeToLiveSeconds: 60
  volumes:
    - name: files
      persistentVolumeClaim:
       claimName: files-volume-pvc
  hadoopConf:
    fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "renanxx1/spark-pa"
  imagePullPolicy: Always
  mainApplicationFile: local:///files/spark_processing_real_time.py
  sparkVersion: "3.1.1"
  restartPolicy:
    type: Never
  driver:
    # envSecretKeyRefs:
    #   AWS_ACCESS_KEY_ID_FB:
    #     name: aws-credentials-fb
    #     key: aws_access_key_id
    #   AWS_SECRET_ACCESS_KEY_FB:
    #     name: aws-credentials-fb
    #     key: aws_secret_access_key

    #   AWS_ACCESS_KEY_ID_CX:
    #     name: aws-credentials-cx
    #     key: aws_access_key_id
    #   AWS_SECRET_ACCESS_KEY_FB:
    #     name: aws-credentials-cx
    #     key: aws_secret_access_key
    cores: 1
    coreLimit: "1200m"
    memory: "2g"
    labels:
      version: 3.1.1
    serviceAccount: spark-operator-spark
    volumeMounts:
      - name: files
        mountPath: /files/
  executor:
    # envSecretKeyRefs:
    #   AWS_ACCESS_KEY_ID_FB:
    #     name: aws-credentials-fb
    #     key: aws_access_key_id
    #   AWS_SECRET_ACCESS_KEY_FB:
    #     name: aws-credentials-fb
    #     key: aws_secret_access_key

    #   AWS_ACCESS_KEY_ID_CX:
    #     name: aws-credentials-cx
    #     key: aws_access_key_id
    #   AWS_SECRET_ACCESS_KEY_FB:
    #     name: aws-credentials-cx
    #     key: aws_secret_access_key
    cores: 2
    instances: 2
    memory: "2g"
    labels:
      version: 3.1.1
    volumeMounts:
      - name: files
        mountPath: /files/
